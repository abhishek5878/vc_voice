# Automated Analyst Memo Generator – Implementation Summary

When `evaluation_complete` is True, the triage flow generates a structured **Investment Memo Fragment** (Analyst Memo), stores it on the Lead, and returns it in the chat API.

## 1. Lead model (`app/models.py`)

`Lead` includes `memo_fragment` as **JSON** (structured dict). Stored on the final turn when evaluation completes.

```python
memo_fragment: Optional[dict] = Field(default=None, sa_column=Column(JSON))
```

If you prefer a single text field, you can add `memo_fragment_text: Optional[str]` and populate it from a rendered version of the memo; the API and UI can use the structured `memo_fragment` for hook, signal_summary, red_flags, and recommendation.

---

## 2. Memo fragment builder (`app/services/memo_fragment.py`)

**Tenant-aware LLM generation:** When `api_key` and `persona_name` are passed, the memo is generated by the LLM using a prompt that references the tenant/persona (e.g. “for Sajith’s deal flow”). Otherwise a rule-based fallback is used.

**Public API:**

```python
build_memo_fragment(state, evaluation, api_key=None, persona_name=None) -> dict
```

**Returned structure:**

- **`hook`**: One-sentence summary of why this founder stands out (or doesn’t).
- **`signal_summary`**: Bulleted list of traction/credentials (from `extracted_signals` / conversation).
- **`red_flags`**: Summary of AI-detection or behavioral anomalies.
- **`recommendation`**:
  - **`priority`**: `"High"` | `"Medium"` | `"Low"`.
  - **`next_step`**: Concrete next step (e.g. “Schedule 15m intro”, “Refer out”, “Polite pass”).

Logic follows patterns from `lib/evaluation.py`: sync OpenAI call, JSON parsing with fallback, and use of transcript + signals + evaluation context.

---

## 3. TriageEngine (`app/services/triage.py`)

- **Import:**  
  `from app.services.memo_fragment import build_memo_fragment`

- **`_run_full_evaluation`** (when building the result dict):  
  After building `result`, generate the memo with the tenant’s API key and persona so the prompt is tenant-aware:

  ```python
  result = {
      **llm_eval,
      "score": scoring["final_score"],
      "recommendation": scoring["recommendation"],
      "recommendation_text": scoring["recommendation_text"],
      "authenticity_score": scoring["authenticity_score"],
      "quality_score": scoring["quality_score"],
      "scoring_factors": scoring["combined_factors"],
      "original_llm_score": llm_score,
  }
  api_key = self._get_api_key()
  persona_name = self._get_persona_name()
  result["memo_fragment"] = build_memo_fragment(
      state, result, api_key=api_key, persona_name=persona_name
  )
  return result
  ```

- **`process_message`** (when evaluation is complete):  
  After `lead.evaluation_result = evaluation`, set:
  ```python
  lead.memo_fragment = evaluation.get("memo_fragment")
  ```

---

## 4. Chat API (`app/api/v1/endpoints/chat.py`)

- **`ChatResponse`:**  
  Include:
  ```python
  memo_fragment: Optional[dict] = None
  ```

- **Return value:**  
  When evaluation is finished, pass the memo in the response:
  ```python
  memo_fragment=result.get("evaluation", {}).get("memo_fragment") if result.get("evaluation_complete") else None,
  ```

---

## 5. Example memo fragment (in response / on Lead)

```json
{
  "hook": "Strong B2B traction with 50 paying customers and clear path to CM2+; worth a short intro.",
  "signal_summary": [
    "50 paying SMB customers",
    "Ex-Razorpay PM",
    "20% MoM growth",
    "Raising seed"
  ],
  "red_flags": ["Moderate AI signals (0.45)"],
  "recommendation": {
    "priority": "Medium",
    "next_step": "Schedule 15m intro"
  }
}
```

- **Priority:** High (recommend_meeting / score ≥ 8), Medium (recommend_if_bandwidth or 6 ≤ score < 8), Low (pass/refer_out).
- **Next step:** Suggested action (e.g. “Schedule 15m intro”, “Refer to other resources”, “Polite pass”).
